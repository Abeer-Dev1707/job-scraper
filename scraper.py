import requests
from bs4 import BeautifulSoup
import json
import time

all_jobs = []

# Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù„ÙŠ Ù†Ø±ÙŠØ¯ Ù†Ø²ÙˆØ±Ù‡Ø§ (Ù…Ø«Ù„Ø§Ù‹ 50 ØµÙØ­Ø© = ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹ Ø¢Ù„Ø§Ù Ø§Ù„ÙˆØ¸Ø§Ø¦Ù)
for page in range(1, 51):
    url = f"https://www.timesjobs.com/candidate/job-search.html?from=submit&actualTxtKeywords=python&searchBy=0&rdoOperator=OR&searchType=personalizedSearch&luceneResultSize=25&postWeek=60&txtKeywords=python&cboWorkExp1=0&pDate=I&sequence={page}&startPage=1"
    
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    jobs = soup.find_all("li", class_="clearfix job-bx wht-shd-bx")

    if not jobs:  # Ù„Ùˆ Ø§Ù„ØµÙØ­Ø© ÙØ§Ø¶ÙŠØ© Ù†ÙˆÙ‚Ù
        print(f"ğŸ”´ Ù…Ø§ ÙÙŠ ÙˆØ¸Ø§Ø¦Ù Ø¨Ø§Ù„ØµÙØ­Ø© {page}ØŒ ÙˆÙ‚ÙÙ†Ø§.")
        break

    for job in jobs:
        job_title = job.find("h2").text.strip() if job.find("h2") else "N/A"
        company = job.find("h3", class_="joblist-comp-name")
        company = company.text.strip() if company else "N/A"
        skills = job.find("span", class_="srp-skills")
        skills = skills.text.strip() if skills else "N/A"
        more_info = job.header.h2.a['href'] if job.header and job.header.h2 and job.header.h2.a else "N/A"

        all_jobs.append({
            "title": job_title,
            "company": company,
            "skills": skills,
            "link": more_info
        })

    print(f"âœ… Ø§Ù„ØµÙØ­Ø© {page} ØªÙ…ØªØŒ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†: {len(all_jobs)}")

    time.sleep(2)  # Ù†Ø±ÙŠØ­ Ø´ÙˆÙŠ Ø¹Ù„Ø´Ø§Ù† Ù…Ø§ ÙŠÙˆÙ‚ÙÙ†Ø§ Ø§Ù„Ù…ÙˆÙ‚Ø¹

# Ø­ÙØ¸ ÙÙŠ JSON
with open("jobs.json", "w", encoding="utf-8") as f:
    json.dump(all_jobs, f, ensure_ascii=False, indent=4)

print(f"ğŸ‰ ØªÙ… Ø¬Ù…Ø¹ {len(all_jobs)} ÙˆØ¸ÙŠÙØ© ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ jobs.json")
